{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eafeca45",
   "metadata": {},
   "source": [
    "This notebooks takes the pickle file of filtered VCF files (SNPS) and reduces the feature space with a Random Forest algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b471d75e-6845-4e01-89c0-b4a6a9a1680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout, Flatten,BatchNormalization, GaussianNoise\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import compute_class_weight\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe4b7d-8b05-488c-9f81-bfba54c7c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading all the SNP files\n",
    "vcf = pd.read_pickle(\"all_vcfs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c5912f-aae0-4d0e-b9ee-d26da2d2c193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the diagnosis data\n",
    "m = pd.read_csv(\"diagnosis_full.csv\").drop(\"Unnamed: 0\", axis=1).rename(columns = {\"Subject\":\"subject\", \"GROUP\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b392fe-2320-483b-aacb-2eeb31ed53be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making sure all the diagnosis agree\n",
    "m = m[m[\"label\"] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35acf7-3f15-4599-8bda-43aa1ba1b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging SNPs with diagnosis\n",
    "vcf = vcf.merge(m[[\"subject\", \"label\"]], on = \"subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4579d195-7a1b-467f-baab-ca83710f445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf = vcf.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d4de7e-c839-49ff-851d-413d9276394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the overlap test set\n",
    "ts = pd.read_csv(\"overlap_test_set.csv\")\n",
    "\n",
    "#removing ids from the overlap test set, saving it as a new variable\n",
    "vcf1 = vcf[~vcf[\"subject\"].isin(list(ts[\"subject\"].values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f3af9e-19c3-483c-a4c5-14a1f5fa44fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Random Forest to reduce feature dimensions\n",
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ddbe80-a329-4b6e-9849-b310cc4b0072",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(set(vcf1.columns) - set([\"subject\", \"Group\", \"label\"]))\n",
    "X = vcf1[cols].values.astype(int)\n",
    "y = vcf1[\"label\"].astype(int).values\n",
    "\n",
    "for i in range(len(y)):\n",
    "    y[i] = y[i]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b65dc28-8a5a-4ac2-91fc-36d241df9555",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f609672d-c2d6-4460-934a-8905f1c6b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting random forest only on the training data so that there is not influence on the testing performance\n",
    "sel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea190c-7873-48ea-828e-3f01a638dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat= X_train.columns[(sel.get_support())]\n",
    "len(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71280302-2794-4874-89d4-adf25472848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c43521-88d8-4120-be0c-5a0cf3ff9819",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = [\"label\", \"subject\", \"Group\"]\n",
    "l.extend(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0410a43-8d76-4180-a7e3-68bca8a33bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the features with the old dataframe so that the overlap test set can still be used when combining all data\n",
    "vcf[l].to_pickle(\"vcf_select.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eaf907-10c0-4c45-bad8-fb4aee33e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle(\"X_train_vcf.pkl\")\n",
    "y_train.to_pickle(\"y_train_vcf.pkl\")\n",
    "\n",
    "X_test.to_pickle(\"X_test_vcf.pkl\")\n",
    "y_test.to_pickle(\"y_test_vcf.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
